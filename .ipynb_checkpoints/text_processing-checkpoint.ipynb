{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0323e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b77b7f",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1220bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "import pprint \n",
    "import os\n",
    "\n",
    "# Import progress bar module\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# Import time and sys modules\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Import BoardGameGeek client\n",
    "from boardgamegeek import BGGClient\n",
    "\n",
    "# Create an instance of the BoardGameGeek client\n",
    "bgg = BGGClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b579a8b",
   "metadata": {},
   "source": [
    "# EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2face6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[9]\n",
      "|████████████████████████████████████████| 15/15 [100%] in 0.0s (118779.57/s)   \n",
      "\n",
      "[10]\n",
      "|████████████████████████████████████████| 14/14 [100%] in 0.0s (88800.16/s)    \n",
      "\n",
      "[11]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[12]\n",
      "|████████████████████████████████████████| 101/101 [100%] in 0.0s (236519.44/s) \n",
      "\n",
      "[13]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[14]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[15]\n",
      "|████████████████████████████████████████| 17/17 [100%] in 0.0s (120718.09/s)   \n",
      "\n",
      "[16]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[17]\n",
      "|████████████████████████████████████████| 93/93 [100%] in 0.0s (162720.01/s)   \n",
      "\n",
      "[18]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[19]\n",
      "|████████████████████████████████████████| 272/272 [100%] in 0.0s (227420.96/s) \n",
      "\n",
      "[20]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[21]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[22]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[23]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[24]\n",
      "|████████████████████████████████████████| 493/493 [100%] in 0.0s (250015.40/s) \n",
      "\n",
      "[25]\n",
      "ERROR - Skipping the rest of the comments...\n",
      "\n",
      "[26]\n",
      "|████████████████████████████████████████| 6354/6354 [100%] in 0.0s (310316.70/s\n",
      "\n",
      "[27]\n",
      "|████████████████████████████████████████| 5938/5938 [100%] in 0.0s (334207.08/s\n",
      "\n",
      "[28]\n",
      "|████████████████████████████████████████| 6176/6176 [100%] in 0.0s (330491.44/s\n",
      "\n",
      "[29]\n",
      "|████████████████████████████████████████| 428/428 [100%] in 0.0s (191427.39/s) \n",
      "\n",
      "[30]\n",
      "|████████████████████████████████████████| 593/593 [100%] in 0.0s (275238.86/s) \n",
      "\n",
      "[31]\n",
      "|████████████████████████████████████████| 3396/3396 [100%] in 0.0s (302138.63/s\n",
      "\n",
      "[32]\n",
      "|████████████████████████████████████████| 11410/11410 [100%] in 0.1s (364462.18\n",
      "\n",
      "[33]\n",
      "|████████████████████████████████████████| 285/285 [100%] in 0.0s (174246.27/s) \n",
      "\n",
      "[34]\n",
      "|████████████████████████████████████████| 600/600 [100%] in 0.0s (236355.18/s) \n",
      "\n",
      "[35]\n",
      "|████████████████████████████████████████| 211/211 [100%] in 0.0s (244348.61/s) \n",
      "\n",
      "[36]\n",
      "|████████████████████████████████████████| 277/277 [100%] in 0.0s (216862.08/s) \n",
      "\n",
      "[37]\n",
      "|████████████████████████████████████████| 2736/2736 [100%] in 0.0s (289160.81/s\n",
      "\n",
      "[38]\n",
      "|████████████████████████████████████████| 34/34 [100%] in 0.0s (132609.08/s)   \n",
      "\n",
      "[39]\n",
      "|████████████████████████████████████████| 455/455 [100%] in 0.0s (250737.23/s) \n",
      "\n",
      "[40]\n",
      "|████████████████████████████████████████| 3902/3902 [100%] in 0.0s (304189.90/s\n",
      "\n",
      "[41]\n",
      "|████████████████████████████████████████| 30/30 [100%] in 0.0s (45657.41/s)    \n",
      "\n",
      "[42]\n",
      "|████████████████████████████████████████| 1835/1835 [100%] in 0.0s (286812.99/s\n",
      "\n",
      "[43]\n",
      "|████████████████████████████████████████| 1384/1384 [100%] in 0.0s (275220.47/s\n",
      "\n",
      "[44]\n",
      "|████████████████████████████████████████| 1574/1574 [100%] in 0.0s (291466.54/s\n",
      "\n",
      "[45]\n",
      "|████████████████████████████████████████| 454/454 [100%] in 0.0s (229480.55/s) \n",
      "\n",
      "[46]\n",
      "|████████████████████████████████████████| 9906/9906 [100%] in 0.1s (349171.39/s\n",
      "\n",
      "[47]\n",
      "|████████████████████████████████████████| 4088/4088 [100%] in 0.1s (32001.81/s)\n",
      "\n",
      "[48]\n",
      "|████████████████████████████████████████| 403/403 [100%] in 0.0s (258776.79/s) \n",
      "\n",
      "[49]\n",
      "|████████████████████████████████████████| 2042/2042 [100%] in 0.0s (309672.83/s\n",
      "\n",
      "[50]\n",
      "|████████████████████████████████████████| 203/203 [100%] in 0.0s (247160.04/s) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the hot items in the 'boardgame' category from BoardGameGeek\n",
    "hot_items = bgg.hot_items('boardgame')\n",
    "\n",
    "# Create an empty dictionary to store items that encounter errors\n",
    "miss = {}\n",
    "\n",
    "# Create an empty list to store the extracted data\n",
    "data = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Iterate over each hot item\n",
    "for item in hot_items:\n",
    "    try:\n",
    "        count = count + 1\n",
    "        print(f'[{count}]')\n",
    "        \n",
    "        # Retrieve the game details, including comments, for the current item\n",
    "        game = bgg.game(game_id=item.id, comments=True)\n",
    "        \n",
    "        # Create a progress bar with the length of the comments\n",
    "        with alive_bar(len(game.comments), force_tty=True) as bar:\n",
    "            \n",
    "            # Iterate over each comment in the game\n",
    "            for comment in game.comments:\n",
    "                # Create a dictionary to store the comment data\n",
    "                com_data = {\n",
    "                    \"id\": item.id,\n",
    "                    \"title\": item.name,\n",
    "                    \"user\": comment.commenter,\n",
    "                    \"comment\": comment.comment,\n",
    "                    \"rating\": comment.rating\n",
    "                }\n",
    "                \n",
    "                # Append the comment data to the list\n",
    "                data.append(com_data)\n",
    "                \n",
    "                # time.sleep(0.01)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                bar()\n",
    "        \n",
    "    except:\n",
    "        # If an error occurs, print 'error' and add the item to the 'miss' dictionary\n",
    "        print('ERROR - Skipping the rest of the comments...\\n')\n",
    "        miss[item.id] = item.name\n",
    "\n",
    "if demo:\n",
    "    # Specify the folder path where you want to save the file\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Specify the filename\n",
    "    filename = \"comment_data_demo.json\"\n",
    "else:\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    filename = \"comment_data.json\"\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the extracted data to the JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(data, f, indent=2)  # indent=2 is not needed but makes the file human-readable if the data is nested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f565491",
   "metadata": {},
   "source": [
    "# WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4bc111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of comments before any formatting: 136806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       title       user  \\\n",
       "0  390478  Gloomhaven: Second Edition  amusedleg   \n",
       "\n",
       "                                      comment rating  \n",
       "0  Day 1 of the GH 2.0 campaign.  Can't wait.    n/a  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set the display option to show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Specify the folder path where you want to save the file\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Specify the filename\n",
    "    filename = \"comment_data_demo.json\"\n",
    "else:\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    filename = \"comment_data.json\"\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Read the JSON file containing the comment data\n",
    "with open(file_path, 'r') as f:\n",
    "    post_list = json.load(f)\n",
    "    \n",
    "# Print the number of comments before any formatting\n",
    "print(f'Amount of comments before any formatting: {len(post_list)}')\n",
    "\n",
    "# Convert the JSON data into a pandas DataFrame\n",
    "df = pd.json_normalize(post_list)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Save the DataFrame as a CSV file in the specified directory\n",
    "    df.to_csv(os.path.join(path_original_data, 'comment_data_demo.csv'), index=False)\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df.to_csv(os.path.join(path_original_data, 'comment_data.csv'), index=False)\n",
    "\n",
    "# Display the first row of the DataFrame\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f531563",
   "metadata": {},
   "source": [
    "# CLEANING\n",
    "\n",
    "## Reading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f144b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       title       user  \\\n",
       "0  390478  Gloomhaven: Second Edition  amusedleg   \n",
       "\n",
       "                                      comment  rating  \n",
       "0  Day 1 of the GH 2.0 campaign.  Can't wait.     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'comment_data_demo.csv'), low_memory=False)\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'comment_data.csv'), low_memory=False)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa118e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99%\n",
      "18588.0\n",
      "1.0\n",
      "202.97686183628562\n",
      "\n",
      "2851\n",
      "2\n",
      "0\n",
      "102       After just one play I get the feeling I have s...\n",
      "146       I really don’t get the hype around Heat, but t...\n",
      "183       An okay \"deck management” game with a relatabl...\n",
      "326       Update: After some more plays I feel that some...\n",
      "435       [imageID=6940449small inline] This really feel...\n",
      "                                ...                        \n",
      "136562    The character progression system is very inter...\n",
      "136659    These are thoughts from a single play through ...\n",
      "136667    This is pure a take that game! don't try to \"p...\n",
      "136718    Too long with 2P. Better with 3P, but the card...\n",
      "136745    Review: Highly interactive, tactical, and stre...\n",
      "Name: comment, Length: 2851, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics of the 'comment' field\n",
    "\n",
    "# Calculate the percentage of non-null comments\n",
    "comment_percentage = round(df.comment.notnull().mean() * 100, 2)\n",
    "print(str(comment_percentage) + '%')\n",
    "\n",
    "# Calculate the maximum, minimum, and mean length of comments\n",
    "max_length = df.comment.str.len().max()\n",
    "min_length = df.comment.str.len().min()\n",
    "mean_length = df.comment.str.len().mean()\n",
    "print(max_length)\n",
    "print(min_length)\n",
    "print(mean_length)\n",
    "print()\n",
    "\n",
    "# Search the number of comments containing searched words within the text of the message\n",
    "\n",
    "pattern = \"random\"\n",
    "\n",
    "# Count comments containing the search pattern\n",
    "contains_pattern = df.comment.str.contains(pattern, na=False).sum()\n",
    "\n",
    "# Count comments starting with the search pattern\n",
    "starts_with_pattern = df.comment.str.startswith(pattern, na=False).sum()\n",
    "\n",
    "# Count comments exactly matching the search pattern\n",
    "exact_match_pattern = df.comment.str.fullmatch(pattern, na=False).sum()\n",
    "\n",
    "print(contains_pattern)\n",
    "print(starts_with_pattern)\n",
    "print(exact_match_pattern)\n",
    "\n",
    "# Filter out rows with null comments and reset the index\n",
    "df = df[df.comment.notnull()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the first messages that contain the pattern\n",
    "matching_comments = df.loc[df.comment.str.contains(pattern, na=False), 'comment']\n",
    "print(matching_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879a8a",
   "metadata": {},
   "source": [
    "## Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd3c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guess_language import guess_language\n",
    "import enchant\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Function to check if a comment is in English\n",
    "def is_english_batch(batch):\n",
    "    # Create a batch of processed texts\n",
    "    processed_texts = batch['comment'].str.lower().str.findall(r\"[a-zA-Z0-9']+\")\n",
    "\n",
    "    # Create an English dictionary\n",
    "    english_dictionary = enchant.Dict(\"en_US\")\n",
    "\n",
    "    # Check if any comment in the batch is in English\n",
    "    is_english = processed_texts.apply(lambda text: sum(english_dictionary.check(word) for word in text) >= len(text) / 2)\n",
    "\n",
    "    # Return a boolean Series indicating if each comment is in English\n",
    "    return is_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c70f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 137/137 [06:55<00:00,  3.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>bark</td>\n",
       "      <td>BGCJ made me do it. Stop making fake dungeon c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Brefs</td>\n",
       "      <td>Cant wait for It, thanks for the amazing job s...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Dali187</td>\n",
       "      <td>A perfect non greed driven game made even more...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>DJ_Tsaladi_Tjatekok</td>\n",
       "      <td>Nem vagyok egy Homályrév-rajongó, de ha már me...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        id                       title                 user  \\\n",
       "0 NaN  390478.0  Gloomhaven: Second Edition            amusedleg   \n",
       "1 NaN  390478.0  Gloomhaven: Second Edition                 bark   \n",
       "2 NaN  390478.0  Gloomhaven: Second Edition                Brefs   \n",
       "3 NaN  390478.0  Gloomhaven: Second Edition              Dali187   \n",
       "4 NaN  390478.0  Gloomhaven: Second Edition  DJ_Tsaladi_Tjatekok   \n",
       "\n",
       "                                             comment  rating  \n",
       "0         Day 1 of the GH 2.0 campaign.  Can't wait.     NaN  \n",
       "1  BGCJ made me do it. Stop making fake dungeon c...     1.0  \n",
       "2  Cant wait for It, thanks for the amazing job s...    10.0  \n",
       "3  A perfect non greed driven game made even more...    10.0  \n",
       "4  Nem vagyok egy Homályrév-rajongó, de ha már me...     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from alive_progress import alive_bar\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 1000  # Number of rows to process in each batch\n",
    "num_rows = len(df)\n",
    "result = pd.Series([], dtype='float64')  # Store the results\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = (num_rows // batch_size) + 1\n",
    "\n",
    "# Initialize a progress bar\n",
    "with tqdm(total=num_batches, ncols=num_batches) as pbar:\n",
    "    # Process each batch\n",
    "    for i in range(0, num_rows, batch_size):\n",
    "        # Extract a batch of rows from the DataFrame\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Filter out non-English rows in the batch\n",
    "        batch_english = batch.loc[is_english_batch(batch)]\n",
    "        \n",
    "        # Concatenate the English rows to the result\n",
    "        result = pd.concat([result, batch_english])\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9607c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check.\n",
      "Check.\n",
      "Current database: 125426\n",
      "Original database: 136787\n",
      "Difference: 11361\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Fuzzel</td>\n",
       "      <td>Unnötige Geldmache mit der erfolgreichen Marke.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>a2greg</td>\n",
       "      <td>nyp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>Abri</td>\n",
       "      <td>56x87mm cards (330pcs)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>alexbatbee</td>\n",
       "      <td>zatu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>ANDREWSOFT</td>\n",
       "      <td>Jugadas varias partidas en solitario con el mó...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                       title        user  \\\n",
       "0  390478.0  Gloomhaven: Second Edition      Fuzzel   \n",
       "1  366013.0    Heat: Pedal to the Metal      a2greg   \n",
       "2  366013.0    Heat: Pedal to the Metal        Abri   \n",
       "3  366013.0    Heat: Pedal to the Metal  alexbatbee   \n",
       "4  366013.0    Heat: Pedal to the Metal  ANDREWSOFT   \n",
       "\n",
       "                                             comment  rating   0  \n",
       "0    Unnötige Geldmache mit der erfolgreichen Marke.     1.0 NaN  \n",
       "1                                                nyp     NaN NaN  \n",
       "2                             56x87mm cards (330pcs)     NaN NaN  \n",
       "3                                               zatu     NaN NaN  \n",
       "4  Jugadas varias partidas en solitario con el mó...     8.2 NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have two DataFrames: df1 and df2 representing the two databases\n",
    "df1 = df\n",
    "# print('Check.')\n",
    "df2 = result\n",
    "# print('Check.')\n",
    "\n",
    "# Print the size of each database\n",
    "print('Current database:', len(result))\n",
    "print('Original database:', len(df))\n",
    "print('Difference:', len(df)-len(result))\n",
    "\n",
    "# Find rows with differing 'comment' in df1 compared to df2\n",
    "diff_df1 = df1[~df1['comment'].isin(df2['comment'])]\n",
    "\n",
    "# Find rows with differing 'comment' in df2 compared to df1\n",
    "diff_df2 = df2[~df2['comment'].isin(df1['comment'])]\n",
    "\n",
    "# Concatenate the differing rows into a single DataFrame\n",
    "diff_combined = pd.concat([diff_df1, diff_df2])\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "diff_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the differences\n",
    "diff_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b32685aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the length of each comment\n",
    "result['text_length'] = result['comment'].apply(lambda x: len(x))  \n",
    "\n",
    "# Add a new column with the word count of each comment\n",
    "result['word_count'] = result['comment'].apply(lambda x: len(x.split())) \n",
    "\n",
    "# Filter out rows with word count less than or equal to 5\n",
    "result = result[result['word_count'] > 5]  \n",
    "\n",
    "# Drop the first column (assumed to be unnecessary)\n",
    "result = result.drop(result.columns[0], axis=1)  \n",
    "\n",
    "# Print the first 5 rows of the resulting DataFrame\n",
    "result.head(5)  \n",
    "\n",
    "# Save the pre-processed DataFrame to a CSV file\n",
    "if demo:\n",
    "    result.to_csv(os.path.join(path_original_data, 'pre_processed_comment_data_demo.csv'), index=False)\n",
    "else:\n",
    "    result.to_csv(os.path.join(path_original_data, 'pre_processed_comment_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7f5b3",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "360ff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set the display option to show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Construct the file path to the CSV file\n",
    "    csv_file_path = os.path.join(path_original_data, 'pre_processed_comment_data_demo.csv')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    csv_file_path = os.path.join(path_original_data, 'pre_processed_comment_data.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47da6c6",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acad253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Function to remove punctuation from a text\n",
    "def remove_punctuation(text):\n",
    "    # Create a set of allowed characters (letters, numbers, and space)\n",
    "    allowed_chars = set(string.ascii_letters + string.digits + ' ')\n",
    "    \n",
    "    # Remove punctuation characters not in the allowed set\n",
    "    processed_text = ''.join(char for char in text if char in allowed_chars)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply the remove_punctuation() function to the 'comment' column and store the result in a new column 'processed_comment'\n",
    "df['processed_comment'] = df['comment'].apply(remove_punctuation)\n",
    "\n",
    "# Lower case all the messages\n",
    "df['processed_comment'] = df['processed_comment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e41eff",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3dd8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to tokenize a text\n",
    "def tokenization(text):\n",
    "    # Split the text on spaces to create tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenization() function to the 'processed_comment' column and store the result in a new column 'comment_tokenized'\n",
    "df['comment_tokenized'] = df['processed_comment'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc435a4",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dccbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "\n",
    "# Download the required NLTK resources (uncomment if needed)\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[0:10])\n",
    "\n",
    "# Defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "# Applying the function\n",
    "df['comment_key_words']= df['comment_tokenized'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6615e",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1e1aa5c",
   "metadata": {},
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Defining the object for stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Defining a function for stemming\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "\n",
    "    return stem_text\n",
    "\n",
    "df['comment_stemmed']= df['comment_key_words'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174db225",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1fff780",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    return lemm_text\n",
    "\n",
    "df['comment_lemmatized']= df['comment_key_words'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db142c",
   "metadata": {},
   "source": [
    "## Gensim preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dae5839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "np.random.seed(400)\n",
    "\n",
    "# Download the required NLTK resource (uncomment if needed)\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "reference_sheet = {}  # Dictionary to store word reference sheet\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Function to lemmatize and stem a word\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize, lemmatize, and filter stopwords\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 2:\n",
    "            word = lemmatize_stemming(token)\n",
    "            if word in reference_sheet:\n",
    "                if token not in reference_sheet[word]:\n",
    "                    reference_sheet[word].append(token)\n",
    "            else:\n",
    "                reference_sheet[word] = [token]\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "# Tokenize, lemmatize, and filter verbs\n",
    "def preprocess_verbs(text):\n",
    "    text = gensim.utils.simple_preprocess(text)\n",
    "    tagged_tokens = nltk.pos_tag(text)\n",
    "    filtered_tokens = [token for token, pos_tag in tagged_tokens if pos_tag not in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "    \n",
    "    result = []\n",
    "    for token in filtered_tokens:\n",
    "        if token not in STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "# print('Start.')\n",
    "df['gensim_comment'] = df['comment'].apply(preprocess)\n",
    "# print('Next.')\n",
    "df['gensim_comment_verbs'] = df['comment'].apply(preprocess_verbs)\n",
    "# print('Finish.')\n",
    "\n",
    "# Save reference sheet as a JSON file\n",
    "json_data = json.dumps(reference_sheet)\n",
    "with open('reference_sheet.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb7aae",
   "metadata": {},
   "source": [
    "## Restructring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78769784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'user', 'comment', 'rating', 'text_length', 'word_count', 'processed_comment', 'comment_tokenized', 'comment_key_words', 'gensim_comment', 'gensim_comment_verbs'] \n",
      "\n",
      "242.00339533107888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>224517.0</td>\n",
       "      <td>Brass: Birmingham</td>\n",
       "      <td>Northwest Smith</td>\n",
       "      <td>Sleeved (Sleeve kings), Folded Space organizer</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>sleeved sleeve kings folded space organizer</td>\n",
       "      <td>['sleeved', 'sleeve', 'kings', 'folded', 'spac...</td>\n",
       "      <td>['sleeved', 'sleeve', 'kings', 'folded', 'spac...</td>\n",
       "      <td>['sleev', 'sleev', 'king', 'fold', 'space', 'o...</td>\n",
       "      <td>['sleev', 'king', 'space', 'organ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71405</th>\n",
       "      <td>291457.0</td>\n",
       "      <td>Gloomhaven: Jaws of the Lion</td>\n",
       "      <td>casadeisogniburritts</td>\n",
       "      <td>Initial rating.  Very good game with just the ...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "      <td>initial rating  very good game with just the r...</td>\n",
       "      <td>['initial', 'rating', 'very', 'good', 'game', ...</td>\n",
       "      <td>['initial', 'rating', 'good', 'game', 'right',...</td>\n",
       "      <td>['initi', 'rat', 'good', 'game', 'right', 'mix...</td>\n",
       "      <td>['initi', 'rat', 'good', 'game', 'right', 'mix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36422</th>\n",
       "      <td>174430.0</td>\n",
       "      <td>Gloomhaven</td>\n",
       "      <td>grunner</td>\n",
       "      <td>My wife and I have fallen in love with every a...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>138</td>\n",
       "      <td>29</td>\n",
       "      <td>my wife and i have fallen in love with every a...</td>\n",
       "      <td>['my', 'wife', 'and', 'i', 'have', 'fallen', '...</td>\n",
       "      <td>['wife', 'fallen', 'love', 'every', 'aspect', ...</td>\n",
       "      <td>['wife', 'fall', 'love', 'aspect', 'game', 'sp...</td>\n",
       "      <td>['wife', 'love', 'aspect', 'game', 'hour']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24587</th>\n",
       "      <td>266192.0</td>\n",
       "      <td>Wingspan</td>\n",
       "      <td>1234567</td>\n",
       "      <td>Boring on my initial plays, though I'm sure wo...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>172</td>\n",
       "      <td>29</td>\n",
       "      <td>boring on my initial plays though im sure woul...</td>\n",
       "      <td>['boring', 'on', 'my', 'initial', 'plays', 'th...</td>\n",
       "      <td>['boring', 'initial', 'plays', 'though', 'im',...</td>\n",
       "      <td>['bore', 'initi', 'play', 'sure', 'better', 'l...</td>\n",
       "      <td>['initi', 'play', 'sure', 'better', 'strategi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62061</th>\n",
       "      <td>230802.0</td>\n",
       "      <td>Azul</td>\n",
       "      <td>LionPacifique</td>\n",
       "      <td>Meh. I mean, don't get me wrong, the design an...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "      <td>meh i mean dont get me wrong the design and pr...</td>\n",
       "      <td>['meh', 'i', 'mean', 'dont', 'get', 'me', 'wro...</td>\n",
       "      <td>['meh', 'mean', 'dont', 'get', 'wrong', 'desig...</td>\n",
       "      <td>['meh', 'mean', 'wrong', 'design', 'present', ...</td>\n",
       "      <td>['meh', 'mean', 'wrong', 'design', 'present', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         title                  user  \\\n",
       "9500   224517.0             Brass: Birmingham       Northwest Smith   \n",
       "71405  291457.0  Gloomhaven: Jaws of the Lion  casadeisogniburritts   \n",
       "36422  174430.0                    Gloomhaven               grunner   \n",
       "24587  266192.0                      Wingspan               1234567   \n",
       "62061  230802.0                          Azul         LionPacifique   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "9500      Sleeved (Sleeve kings), Folded Space organizer     8.0           46   \n",
       "71405  Initial rating.  Very good game with just the ...     7.5          114   \n",
       "36422  My wife and I have fallen in love with every a...    10.0          138   \n",
       "24587  Boring on my initial plays, though I'm sure wo...     6.0          172   \n",
       "62061  Meh. I mean, don't get me wrong, the design an...     6.5          160   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "9500            6        sleeved sleeve kings folded space organizer   \n",
       "71405          20  initial rating  very good game with just the r...   \n",
       "36422          29  my wife and i have fallen in love with every a...   \n",
       "24587          29  boring on my initial plays though im sure woul...   \n",
       "62061          30  meh i mean dont get me wrong the design and pr...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "9500   ['sleeved', 'sleeve', 'kings', 'folded', 'spac...   \n",
       "71405  ['initial', 'rating', 'very', 'good', 'game', ...   \n",
       "36422  ['my', 'wife', 'and', 'i', 'have', 'fallen', '...   \n",
       "24587  ['boring', 'on', 'my', 'initial', 'plays', 'th...   \n",
       "62061  ['meh', 'i', 'mean', 'dont', 'get', 'me', 'wro...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "9500   ['sleeved', 'sleeve', 'kings', 'folded', 'spac...   \n",
       "71405  ['initial', 'rating', 'good', 'game', 'right',...   \n",
       "36422  ['wife', 'fallen', 'love', 'every', 'aspect', ...   \n",
       "24587  ['boring', 'initial', 'plays', 'though', 'im',...   \n",
       "62061  ['meh', 'mean', 'dont', 'get', 'wrong', 'desig...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "9500   ['sleev', 'sleev', 'king', 'fold', 'space', 'o...   \n",
       "71405  ['initi', 'rat', 'good', 'game', 'right', 'mix...   \n",
       "36422  ['wife', 'fall', 'love', 'aspect', 'game', 'sp...   \n",
       "24587  ['bore', 'initi', 'play', 'sure', 'better', 'l...   \n",
       "62061  ['meh', 'mean', 'wrong', 'design', 'present', ...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "9500                 ['sleev', 'king', 'space', 'organ']  \n",
       "71405  ['initi', 'rat', 'good', 'game', 'right', 'mix...  \n",
       "36422         ['wife', 'love', 'aspect', 'game', 'hour']  \n",
       "24587  ['initi', 'play', 'sure', 'better', 'strategi'...  \n",
       "62061  ['meh', 'mean', 'wrong', 'design', 'present', ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "columns = list(df.columns)\n",
    "print(columns, '\\n')\n",
    "\n",
    "# Filter the DataFrame based on the length of 'gensim_comment' column\n",
    "df = df[df['gensim_comment'].map(lambda d: len(d)) >= 5]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Calculate the average length of 'gensim_comment' column\n",
    "average_length = df['gensim_comment'].apply(lambda x: len(x)).mean()\n",
    "print(average_length)\n",
    "\n",
    "if demo:\n",
    "     # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(os.path.join(path_original_data, 'post_processed_comment_data_demo.csv'), index=False)\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df.to_csv(os.path.join(path_original_data, 'post_processed_comment_data.csv'), index=False)\n",
    "\n",
    "# Display a sample of 5 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab1836cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47191</th>\n",
       "      <td>199792.0</td>\n",
       "      <td>Everdell</td>\n",
       "      <td>ytjunkies</td>\n",
       "      <td>The amazing art cannot be overstated. The game...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1028</td>\n",
       "      <td>171</td>\n",
       "      <td>the amazing art cannot be overstated the game ...</td>\n",
       "      <td>['the', 'amazing', 'art', 'cannot', 'be', 'ove...</td>\n",
       "      <td>['amazing', 'art', 'cannot', 'overstated', 'ga...</td>\n",
       "      <td>['amaz', 'art', 'overst', 'game', 'gorgeous', ...</td>\n",
       "      <td>['amaz', 'art', 'game', 'gorgeous', 'compon', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26093</th>\n",
       "      <td>266192.0</td>\n",
       "      <td>Wingspan</td>\n",
       "      <td>dustmonster</td>\n",
       "      <td>Great, clever game. Different than so many oth...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>great clever game different than so many other...</td>\n",
       "      <td>['great', 'clever', 'game', 'different', 'than...</td>\n",
       "      <td>['great', 'clever', 'game', 'different', 'many...</td>\n",
       "      <td>['great', 'clever', 'game', 'differ', 'game']</td>\n",
       "      <td>['great', 'clever', 'game', 'differ', 'game']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71408</th>\n",
       "      <td>291457.0</td>\n",
       "      <td>Gloomhaven: Jaws of the Lion</td>\n",
       "      <td>Castanza</td>\n",
       "      <td>This is my first time playing a campaign game....</td>\n",
       "      <td>8.5</td>\n",
       "      <td>228</td>\n",
       "      <td>40</td>\n",
       "      <td>this is my first time playing a campaign game ...</td>\n",
       "      <td>['this', 'is', 'my', 'first', 'time', 'playing...</td>\n",
       "      <td>['first', 'time', 'playing', 'campaign', 'game...</td>\n",
       "      <td>['time', 'play', 'campaign', 'game', 'great', ...</td>\n",
       "      <td>['time', 'campaign', 'game', 'great', 'experi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>MacTele</td>\n",
       "      <td>Great game. The system is great. Heat is brill...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>143</td>\n",
       "      <td>27</td>\n",
       "      <td>great game the system is great heat is brillan...</td>\n",
       "      <td>['great', 'game', 'the', 'system', 'is', 'grea...</td>\n",
       "      <td>['great', 'game', 'system', 'great', 'heat', '...</td>\n",
       "      <td>['great', 'game', 'great', 'heat', 'brillant',...</td>\n",
       "      <td>['great', 'game', 'great', 'heat', 'brillant',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44868</th>\n",
       "      <td>199792.0</td>\n",
       "      <td>Everdell</td>\n",
       "      <td>Elonka</td>\n",
       "      <td>On my first play, quite enjoyed it, there were...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>141</td>\n",
       "      <td>27</td>\n",
       "      <td>on my first play quite enjoyed it there were m...</td>\n",
       "      <td>['on', 'my', 'first', 'play', 'quite', 'enjoye...</td>\n",
       "      <td>['first', 'play', 'quite', 'enjoyed', 'many', ...</td>\n",
       "      <td>['play', 'enjoy', 'way', 'thing', 'work', 'art...</td>\n",
       "      <td>['play', 'way', 'thing', 'art', 'love', 'happi']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         title         user  \\\n",
       "47191  199792.0                      Everdell    ytjunkies   \n",
       "26093  266192.0                      Wingspan  dustmonster   \n",
       "71408  291457.0  Gloomhaven: Jaws of the Lion     Castanza   \n",
       "334    366013.0      Heat: Pedal to the Metal      MacTele   \n",
       "44868  199792.0                      Everdell       Elonka   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "47191  The amazing art cannot be overstated. The game...     9.0         1028   \n",
       "26093  Great, clever game. Different than so many oth...    10.0           55   \n",
       "71408  This is my first time playing a campaign game....     8.5          228   \n",
       "334    Great game. The system is great. Heat is brill...     6.0          143   \n",
       "44868  On my first play, quite enjoyed it, there were...     9.0          141   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "47191         171  the amazing art cannot be overstated the game ...   \n",
       "26093           9  great clever game different than so many other...   \n",
       "71408          40  this is my first time playing a campaign game ...   \n",
       "334            27  great game the system is great heat is brillan...   \n",
       "44868          27  on my first play quite enjoyed it there were m...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "47191  ['the', 'amazing', 'art', 'cannot', 'be', 'ove...   \n",
       "26093  ['great', 'clever', 'game', 'different', 'than...   \n",
       "71408  ['this', 'is', 'my', 'first', 'time', 'playing...   \n",
       "334    ['great', 'game', 'the', 'system', 'is', 'grea...   \n",
       "44868  ['on', 'my', 'first', 'play', 'quite', 'enjoye...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "47191  ['amazing', 'art', 'cannot', 'overstated', 'ga...   \n",
       "26093  ['great', 'clever', 'game', 'different', 'many...   \n",
       "71408  ['first', 'time', 'playing', 'campaign', 'game...   \n",
       "334    ['great', 'game', 'system', 'great', 'heat', '...   \n",
       "44868  ['first', 'play', 'quite', 'enjoyed', 'many', ...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "47191  ['amaz', 'art', 'overst', 'game', 'gorgeous', ...   \n",
       "26093      ['great', 'clever', 'game', 'differ', 'game']   \n",
       "71408  ['time', 'play', 'campaign', 'game', 'great', ...   \n",
       "334    ['great', 'game', 'great', 'heat', 'brillant',...   \n",
       "44868  ['play', 'enjoy', 'way', 'thing', 'work', 'art...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "47191  ['amaz', 'art', 'game', 'gorgeous', 'compon', ...  \n",
       "26093      ['great', 'clever', 'game', 'differ', 'game']  \n",
       "71408  ['time', 'campaign', 'game', 'great', 'experi'...  \n",
       "334    ['great', 'game', 'great', 'heat', 'brillant',...  \n",
       "44868   ['play', 'way', 'thing', 'art', 'love', 'happi']  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'post_processed_comment_data_demo.csv'), low_memory=False)\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'post_processed_comment_data.csv'), low_memory=False)\n",
    "\n",
    "# Display a sample of 10 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9919f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097\n",
      "2755\n",
      "1185\n",
      "3057\n",
      "868\n",
      "130\n",
      "\n",
      "1177\n",
      "2136\n",
      "5469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22692</th>\n",
       "      <td>312484.0</td>\n",
       "      <td>Lost Ruins of Arnak</td>\n",
       "      <td>EHngel</td>\n",
       "      <td>I'm loving this at the moment. I was initially...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>585</td>\n",
       "      <td>93</td>\n",
       "      <td>im loving this at the moment i was initially d...</td>\n",
       "      <td>['im', 'loving', 'this', 'at', 'the', 'moment'...</td>\n",
       "      <td>['im', 'loving', 'moment', 'initially', 'doubt...</td>\n",
       "      <td>['love', 'moment', 'initi', 'doubt', 'enjoy', ...</td>\n",
       "      <td>['moment', 'initi', 'doubt', 'game', 'solo', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61603</th>\n",
       "      <td>230802.0</td>\n",
       "      <td>Azul</td>\n",
       "      <td>Jmccue</td>\n",
       "      <td>A tile selecting and placing game with extreme...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>583</td>\n",
       "      <td>110</td>\n",
       "      <td>a tile selecting and placing game with extreme...</td>\n",
       "      <td>['a', 'tile', 'selecting', 'and', 'placing', '...</td>\n",
       "      <td>['tile', 'selecting', 'placing', 'game', 'extr...</td>\n",
       "      <td>['tile', 'select', 'place', 'game', 'extrem', ...</td>\n",
       "      <td>['tile', 'select', 'place', 'game', 'extrem', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47106</th>\n",
       "      <td>199792.0</td>\n",
       "      <td>Everdell</td>\n",
       "      <td>Werbaer</td>\n",
       "      <td>base rating: 5.5 - average, slightly boring, l...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177</td>\n",
       "      <td>34</td>\n",
       "      <td>base rating 55  average slightly boring luck f...</td>\n",
       "      <td>['base', 'rating', '55', 'average', 'slightly'...</td>\n",
       "      <td>['base', 'rating', '55', 'average', 'slightly'...</td>\n",
       "      <td>['base', 'rat', 'averag', 'slight', 'bore', 'l...</td>\n",
       "      <td>['base', 'rat', 'averag', 'slight', 'bore', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>316554.0</td>\n",
       "      <td>Dune: Imperium</td>\n",
       "      <td>SirHandsome</td>\n",
       "      <td>Removes agency from worker placement, defeatin...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>674</td>\n",
       "      <td>120</td>\n",
       "      <td>removes agency from worker placement defeating...</td>\n",
       "      <td>['removes', 'agency', 'from', 'worker', 'place...</td>\n",
       "      <td>['removes', 'agency', 'worker', 'placement', '...</td>\n",
       "      <td>['remov', 'agenc', 'worker', 'placement', 'def...</td>\n",
       "      <td>['remov', 'agenc', 'worker', 'placement', 'pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40029</th>\n",
       "      <td>174430.0</td>\n",
       "      <td>Gloomhaven</td>\n",
       "      <td>Uncivil</td>\n",
       "      <td>Not my type of game, I don't like long sloggis...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>983</td>\n",
       "      <td>176</td>\n",
       "      <td>not my type of game i dont like long sloggish ...</td>\n",
       "      <td>['not', 'my', 'type', 'of', 'game', 'i', 'dont...</td>\n",
       "      <td>['type', 'game', 'dont', 'like', 'long', 'slog...</td>\n",
       "      <td>['type', 'game', 'like', 'long', 'sloggish', '...</td>\n",
       "      <td>['type', 'game', 'like', 'long', 'sloggish', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                title         user  \\\n",
       "22692  312484.0  Lost Ruins of Arnak       EHngel   \n",
       "61603  230802.0                 Azul       Jmccue   \n",
       "47106  199792.0             Everdell      Werbaer   \n",
       "6784   316554.0       Dune: Imperium  SirHandsome   \n",
       "40029  174430.0           Gloomhaven      Uncivil   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "22692  I'm loving this at the moment. I was initially...    10.0          585   \n",
       "61603  A tile selecting and placing game with extreme...     3.0          583   \n",
       "47106  base rating: 5.5 - average, slightly boring, l...     4.0          177   \n",
       "6784   Removes agency from worker placement, defeatin...     3.0          674   \n",
       "40029  Not my type of game, I don't like long sloggis...     3.0          983   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "22692          93  im loving this at the moment i was initially d...   \n",
       "61603         110  a tile selecting and placing game with extreme...   \n",
       "47106          34  base rating 55  average slightly boring luck f...   \n",
       "6784          120  removes agency from worker placement defeating...   \n",
       "40029         176  not my type of game i dont like long sloggish ...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "22692  ['im', 'loving', 'this', 'at', 'the', 'moment'...   \n",
       "61603  ['a', 'tile', 'selecting', 'and', 'placing', '...   \n",
       "47106  ['base', 'rating', '55', 'average', 'slightly'...   \n",
       "6784   ['removes', 'agency', 'from', 'worker', 'place...   \n",
       "40029  ['not', 'my', 'type', 'of', 'game', 'i', 'dont...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "22692  ['im', 'loving', 'moment', 'initially', 'doubt...   \n",
       "61603  ['tile', 'selecting', 'placing', 'game', 'extr...   \n",
       "47106  ['base', 'rating', '55', 'average', 'slightly'...   \n",
       "6784   ['removes', 'agency', 'worker', 'placement', '...   \n",
       "40029  ['type', 'game', 'dont', 'like', 'long', 'slog...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "22692  ['love', 'moment', 'initi', 'doubt', 'enjoy', ...   \n",
       "61603  ['tile', 'select', 'place', 'game', 'extrem', ...   \n",
       "47106  ['base', 'rat', 'averag', 'slight', 'bore', 'l...   \n",
       "6784   ['remov', 'agenc', 'worker', 'placement', 'def...   \n",
       "40029  ['type', 'game', 'like', 'long', 'sloggish', '...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "22692  ['moment', 'initi', 'doubt', 'game', 'solo', '...  \n",
       "61603  ['tile', 'select', 'place', 'game', 'extrem', ...  \n",
       "47106  ['base', 'rat', 'averag', 'slight', 'bore', 'l...  \n",
       "6784   ['remov', 'agenc', 'worker', 'placement', 'pur...  \n",
       "40029  ['type', 'game', 'like', 'long', 'sloggish', '...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of posts that contain specific words\n",
    "print(len(df[df.comment.str.contains('luck')]))\n",
    "print(len(df[df.comment.str.contains('random')]))\n",
    "print(len(df[df.comment.str.contains('boring')]))\n",
    "print(len(df[df.comment.str.contains('complex')]))\n",
    "print(len(df[df.comment.str.contains('complicated')]))\n",
    "print(len(df[df.comment.str.contains('bookkeeping')]))\n",
    "print()\n",
    "print(len(df[df.comment.str.contains('edition')]))\n",
    "print(len(df[df.comment.str.contains('version')]))\n",
    "print(len(df[df.comment.str.contains('expansion')]))\n",
    "\n",
    "# Display a sample of 5 rows from the DataFrame that contain the word 'boring'\n",
    "df[df.comment.str.contains('boring')].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa51f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
